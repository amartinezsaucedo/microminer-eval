{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"semantic-router[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../jpetstore\"\n",
    "PROJECT_NAME = \"jpetstore\"\n",
    "GROQ_API_KEY = \"yourapikey\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "from semantic_router.layer import RouteLayer\n",
    "from IPython.display import Markdown\n",
    "from ema_workbench import load_results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import pickle\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecompositionSpace:\n",
    "    def __init__(self, project_path, project_name):\n",
    "        model_filename = f\"{project_path}/{project_name}_128scenarios_nopolicies_sobol\" #.tar.gz'\n",
    "        experiments_df, outcomes = load_results(model_filename+ '.tar.gz')\n",
    "        self.outcomes = pd.DataFrame(outcomes)\n",
    "        self.experiments = experiments_df\n",
    "        self.all = pd.concat([experiments_df, self.outcomes], axis=1)\n",
    "        self.all.index = self.all.apply(lambda row: f\"resolution_{row['resolution']}_k_{row['k']}\", axis=1)\n",
    "        with open(model_filename+'_model.pkl', 'rb') as input:\n",
    "            self.uncertainties_problem = pickle.load(input)\n",
    "        with open(model_filename+'_partitions.pkl', 'rb') as input:\n",
    "            self.partitions = pickle.load(input)\n",
    "        similarity_filename = f\"{project_path}/{project_name}_omega_scores.csv\"\n",
    "        self.partitions_distance = 1 - pd.read_csv(similarity_filename, index_col=0)\n",
    "        stable_solutions_filename = f\"{project_path}/{project_name}_stable_solutions.pkl\"\n",
    "        with open(stable_solutions_filename, 'rb') as f:\n",
    "             self.stable_solutions = pickle.load(f)\n",
    "             self.other_labels = self.stable_solutions.keys()\n",
    "             self.all['stability'] = 0\n",
    "             for index, value in self.stable_solutions.items():\n",
    "                 self.all.loc[index, 'stability'] = value \n",
    "        mds = MDS(dissimilarity='precomputed', random_state=0)\n",
    "        self.embeddings_2d_partitions = mds.fit_transform(self.partitions_distance)\n",
    "        partition_labels_2d, _, silhouette = self.run_agglomerative(self.embeddings_2d_partitions, k=5, threshold=None, \n",
    "                                                       show_dendogram=True, normalize=True, n_pca=2)\n",
    "        self.partition_labels = partition_labels_2d\n",
    "\n",
    "    def run_agglomerative(self, df, k, threshold=200, n_pca=None, normalize=False, show_dendogram=False, archstructure=None):    \n",
    "      if normalize:\n",
    "        sample = StandardScaler().fit_transform(df)\n",
    "      else:\n",
    "        sample = df.values\n",
    "    \n",
    "      if n_pca is not None:\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        sample_pca = sample\n",
    "        model = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='ward',\n",
    "                                        connectivity=archstructure, distance_threshold=threshold)\n",
    "        model.fit(sample_pca)\n",
    "        X = sample_pca\n",
    "      else:\n",
    "        model = AgglomerativeClustering(n_clusters=k, affinity='precomputed', linkage='single',\n",
    "                                      connectivity=archstructure, distance_threshold=threshold)\n",
    "        model.fit(sample)\n",
    "      labels = model.labels_\n",
    "      fixed_labels = np.where(model.labels_ < 0, 0, model.labels_)\n",
    "      classes = set(fixed_labels)\n",
    "      if len(classes) > 1:\n",
    "        if n_pca is not None:\n",
    "          silhouette = metrics.silhouette_score(sample_pca, fixed_labels)\n",
    "        else:\n",
    "          silhouette = metrics.silhouette_score(sample, fixed_labels)\n",
    "      else:\n",
    "        silhouette = 0.0    \n",
    "      return fixed_labels, model, silhouette\n",
    "\n",
    "    def get_decompositions_by_metric(self, metric: str, k: int, asc: bool) -> list:\n",
    "        return self.all.sort_values(by=[metric], ascending=[asc]).head(k)\n",
    "\n",
    "    def get_stable_solutions(self, k: int, asc: bool) -> list:\n",
    "        pass\n",
    "\n",
    "    def get_xy_coordinates(self, labels, embeddings_2d, distance_df):\n",
    "        xy_coordinates = []\n",
    "        for lb in labels:\n",
    "            idx = list(distance_df.columns).index(lb)\n",
    "            xy_coordinates.append(embeddings_2d[idx])\n",
    "        return xy_coordinates\n",
    "\n",
    "    def get_decomposition_space(self, labels: [] = []) -> plt.plot: \n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        df = pd.DataFrame(self.embeddings_2d_partitions, columns=['x', 'y'])\n",
    "        df['cluster'] = self.partition_labels \n",
    "        ax = sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", alpha=0.3, legend='full', sizes=(20, 200))\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(ylabel=None)\n",
    "        if len(labels) > 0:\n",
    "            medoids = np.array(self.get_xy_coordinates(labels, self.embeddings_2d_partitions, self.partitions_distance))\n",
    "            ax.plot(medoids[:,0], medoids[:,1], 'X', markersize=9, alpha=0.7, color='black')\n",
    "            for idx, lb in enumerate(labels):\n",
    "                    ax.annotate(lb, (medoids[idx,0], medoids[idx,1]))\n",
    "            \n",
    "        plt.grid(False)\n",
    "        return plt\n",
    "\n",
    "    #TODO translate/map quality attributes to metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SemanticLayer:\n",
    "    SYSTEM_PROMPT = \"\"\"Your are an expert software architect that assists users to explore and understand a de.\n",
    "        You have a deep understanding of monolith to microservices migration and microservices quality metrics.\n",
    "        Your role is to help users to understand the decomposition space to pick the most suitable microservices decomposition according to the user need.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, decomposition_space=None) -> None:\n",
    "        self.llm = Groq(model=\"llama3-8b-8192\", api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "        self.agent = None\n",
    "        self.intent_detector = None\n",
    "        self.decomposition_space = decomposition_space\n",
    "\n",
    "\n",
    "    def show_decomposition_space(self) -> plt.plot:\n",
    "        \"\"\" Gets the decomposition space (plot)\n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space\n",
    "        \"\"\"\n",
    "        return self.decomposition_space.get_decomposition_space().show()\n",
    "\n",
    "    def get_decomposition_by_metric(self, k: int, metric: str, asc: bool) -> pd.DataFrame:\n",
    "        \"\"\" Gets the K decompositions matching a metric condition\n",
    "\n",
    "          Args:\n",
    "            k (int): The number of decompositions to retrieve.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to obtain the decompositions that match a metric higher or lower\n",
    "    \n",
    "        Returns:\n",
    "            pd.DataFrame: The K decompositions ordered by asc param against the metric passed as parameter.\n",
    "        \"\"\"\n",
    "        return self.decomposition_space.get_decompositions_by_metric(metric, k, asc)\n",
    "\n",
    "    def show_decomposition_in_space(self, k: int, metric: str, asc: bool) -> plt.plot:\n",
    "        \"\"\" Show in the decomposition space (plot) the desired K decompositions matching a metric condition\n",
    "\n",
    "        Args:\n",
    "            k (int): The number of decompositions to show.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to show the decompositions that match a metric higher or lower\n",
    "    \n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space with the decompositions found\n",
    "        \"\"\"\n",
    "        decompositions = self.decomposition_space.get_decompositions_by_metric(metric, k, asc)\n",
    "        indexes = decompositions.index.values\n",
    "        labels = []\n",
    "        for index in indexes:\n",
    "            value = self.decomposition_space.experiments.iloc[index]\n",
    "            labels.append(f\"resolution_{value['resolution']}_k_{value['k']}\")\n",
    "        return self.decomposition_space.get_decomposition_space(labels).show()\n",
    "\n",
    "   \n",
    "    def _get_tools(self):\n",
    "        return [ # All the functions that the agent can execute\n",
    "            FunctionTool.from_defaults(fn=self.show_decomposition_space, return_direct=True),\n",
    "            FunctionTool.from_defaults(fn=self.get_decomposition_by_metric, return_direct=True),\n",
    "            FunctionTool.from_defaults(fn=self.show_decomposition_in_space, return_direct=True),\n",
    "        ]\n",
    "\n",
    "    def _configure_routes():\n",
    "        return [\n",
    "            Route(\n",
    "                name=\"show_decomposition_space\",\n",
    "                utterances=[\n",
    "                    \"Which decompositions are generated?\",\n",
    "                    \"Show me the decomposition space graphically\",\n",
    "                    \"Get all decompositions graphically\",\n",
    "                    \"Show me all decompositions\",\n",
    "                    \"Show the decomposition space\",\n",
    "                    \"Show the decomposition space graphically\"\n",
    "                ],\n",
    "                description=\"Show the decomposition space graphically.\"\n",
    "            ),\n",
    "            Route(\n",
    "                name=\"get_decomposition_by_metric\",\n",
    "                utterances=[\n",
    "                    \"Get the X decompositions with less Y\",\n",
    "                    \"Get me X decompositions with more Y\",\n",
    "                    \"Which is the decomposition with more X?\",\n",
    "                    \"Which is the decomposition with less X?\",\n",
    "                    \"Which is the decomposition of highest X?\",\n",
    "                    \"Which is the decomposition of lowest X?\",\n",
    "                ],\n",
    "                description=\"Get the K decompositions that match a preferring metric.\"\n",
    "            ),\n",
    "            Route(\n",
    "                name=\"show_decomposition_in_space\",\n",
    "                utterances=[\n",
    "                    \"Show me the decomposition with more X\",\n",
    "                    \"Get a plot of the decomposition X\",\n",
    "                    \"Show me the decomposition with more X graphically\",\n",
    "                    \"Show me the decomposition with lowest X graphically\",\n",
    "                    \"Show me the decomposition with highest X graphically\",\n",
    "                    \"Show me the decomposition of lowest X graphically\",\n",
    "                    \"Show me the decomposition of highest X graphically\",\n",
    "                ],\n",
    "                description=\"Show the K decompositions that match a preferring metric in the decomposition space.\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.agent.reset()\n",
    "\n",
    "    def chat(self, question, return_intent=False):\n",
    "        if self.agent is None: \n",
    "            tools = self._get_tools()\n",
    "            self.agent = OpenAIAgent.from_tools(tools, llm=self.llm, system_prompt=SemanticLayer.SYSTEM_PROMPT, verbose=True)\n",
    "            encoder = HuggingFaceEncoder()\n",
    "            self.intent_detector = RouteLayer(encoder=encoder, routes=SemanticLayer._configure_routes(), llm=self.llm)\n",
    "\n",
    "        intent  = self.intent_detector(question)\n",
    "        print(\"Intent detected:\", intent.name)\n",
    "\n",
    "        if intent.name is None:\n",
    "            msg = \"I'm sorry, I did not understand your question or I'm no able to answer it. Please try again...\"\n",
    "            if return_intent:\n",
    "                return None\n",
    "            return display(Markdown(f\"<b>{msg}</b>\"))\n",
    "\n",
    "        function_name = \"\\nTry to execute tool \"+intent.name if (intent.name is not None) and (intent.name != 'misc') else \"\"\n",
    "        response = self.agent.chat(question+function_name)\n",
    "\n",
    "        if response.sources is None or len(response.sources) == 0:\n",
    "            return display(Markdown(f\"<b>{response.response}</b>\"))\n",
    "\n",
    "        obj = response.sources[0].raw_output\n",
    "\n",
    "        show_op = getattr(obj, \"show\", None)\n",
    "        if callable(show_op):\n",
    "            msg =  \"This is a graphical representation of the results for your question.\"\n",
    "            display(Markdown(f\"<b>{msg}</b>\"))\n",
    "            show_op()\n",
    "            return None\n",
    "        if return_intent:\n",
    "            return intent.name, response.sources[0].raw_input.get(\"kwargs\"), response\n",
    "        return obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decomposition_space = DecompositionSpace(PROJECT_PATH, PROJECT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer = SemanticLayer(decomposition_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Which is the most unstable decomposition?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Get the 10 decompositions with higher density\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Get the decomposition with lowest ned\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Which is the decomposition of highest modularity?\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Show me the decomposition with highest density graphically\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Show me the 10 decompositions with lowest modularity graphically\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(layer.chat(\"Show me the 10 decompositions with lowest modularity graphically\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, RelevancyEvaluator\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Response\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.prompts.base import BasePromptTemplate, PromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Settings.llm = Groq(model=\"llama3-8b-8192\", api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEFAULT_TEXT_QA_PROMPT = \"\"\"\\\n",
    "Context information is below.\n",
    "You are an expert software architect that assists users to explore and understand a decomposition space.\n",
    "You have a deep understanding of monolith to microservices migration and microservices quality metrics.\n",
    "Your role is to help users to understand the decomposition space to pick the most suitable microservices decomposition according to the user need.\n",
    "The only available metrics are ned, density, modularity, stability, and number of partitions (n_partitions)\n",
    "Just answer with the questions and answers in a Q: A: format, nothing else\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Based on the following function documentation, generate natural questions that someone might ask and this function answer. \n",
    "The answer should always be the function name along its arguments indicating args names. \n",
    "The questions should relate to its description and expected outcomes in a conversational manner, also to the example questions.\n",
    "Do not include args not listed in the function documentation.\n",
    "If based on the documentation a function can not be used to answer the question, return an empty string (\"\").\n",
    "The documentation is as follows\n",
    "{query_str}\n",
    "\"\"\"\n",
    "text_question_template = PromptTemplate(DEFAULT_TEXT_QA_PROMPT)\n",
    "text_qa_template = DEFAULT_TEXT_QA_PROMPT\n",
    "question_gen_query = (f\"You are a Teacher/Professor. Your task is to setup \\\n",
    "                        just 10 questions for an upcoming \\\n",
    "                        quiz/examination. The questions should be diverse in nature \\\n",
    "                            across the document. Restrict the questions to the \\\n",
    "                                context information provided. Tip: use the example questions as inspiration\" )\n",
    "    \n",
    "documentation = [Document(text=\"\"\"\n",
    "        Function: show_decomposition_in_space\n",
    "        Example questions:  \"Show me the decomposition with more X\",\n",
    "                    \"Get a plot of the decomposition X\",\n",
    "                    \"Show me the decomposition with more X graphically\",\n",
    "                    \"Show me the decomposition with lowest X graphically\",\n",
    "                    \"Show me the decomposition with highest X graphically\",\n",
    "                    \"Show me the decomposition of lowest X graphically\",\n",
    "                    \"Show me the decomposition of highest X graphically\",\n",
    "        Description: Show in the decomposition space (plot) the desired K decompositions matching a metric condition\n",
    "        Args:\n",
    "            k (int): The number of decompositions to show.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to show the decompositions that match a metric higher or lower\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space with the decompositions found\"\"\"),\n",
    "                Document(text=\"\"\"\n",
    "                Function: get_decomposition_by_metric\n",
    "                Example questions:  \"Get the X decompositions with less Y\",\n",
    "                    \"Get me X decompositions with more Y\",\n",
    "                    \"Which is the decomposition with more X?\",\n",
    "                    \"Which is the decomposition with less X?\",\n",
    "                    \"Which is the decomposition of highest X?\",\n",
    "                    \"Which is the decomposition of lowest X?\",\n",
    "                Description: Gets the K decompositions matching a metric condition\n",
    "                Args:\n",
    "                    k (int): The number of decompositions to retrieve.\n",
    "                    metric (str): The metric to match the decompositions against.\n",
    "                    asc (bool): Whether to obtain the decompositions that match a metric higher or lower\n",
    "            Returns:\n",
    "                pd.DataFrame: The K decompositions ordered by asc param against the metric passed as parameter.\n",
    "            \"\"\"),\n",
    "                Document(text=\"\"\"\n",
    "                Function: show_decomposition_space\n",
    "                Example questions:  \"Which decompositions are generated?\",\n",
    "                    \"Show me the decomposition space graphically\",\n",
    "                    \"Get all decompositions graphically\",\n",
    "                    \"Show me all decompositions\",\n",
    "                    \"Show the decomposition space\",\n",
    "                    \"Show the decomposition space graphically\"\n",
    "                Description: Gets the decomposition space (plot)\n",
    "                Returns:\n",
    "                    plt.plot: The plot of the decomposition space\n",
    "            \"\"\")]\n",
    "data_generator = DatasetGenerator.from_documents(documentation, text_question_template=text_question_template, text_qa_template=text_qa_template, question_gen_query=question_gen_query)\n",
    "questions = data_generator.generate_questions_from_nodes()\n",
    "questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions = [s for s in questions if s.startswith(\"Q\") or s.startswith(\"A\")]\n",
    "questions = [value.split(\": \")[1] for value in questions]\n",
    "questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "queries = []\n",
    "responses = []\n",
    "references = [] \n",
    "\n",
    "def pairwise(iterable):\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "for query, reference in pairwise(questions):\n",
    "    try:\n",
    "        response_vector, args, _ = layer.chat(query, return_intent=True)\n",
    "        response = f\"{response_vector}(\"\n",
    "        response += ', '.join(f\"{key}={value!r}\" for key, value in args.items())\n",
    "        response += \")\"\n",
    "        responses.append(response)\n",
    "        # TODO should we reset the agent?\n",
    "    except: \n",
    "        responses.append(\"None\")\n",
    "    finally:\n",
    "        queries.append(query)\n",
    "        references.append(reference)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from llama_index.core.evaluation.dataset_generation import QueryResponseDataset\n",
    "\n",
    "dataset = QueryResponseDataset.from_qr_pairs(list(zip(queries, responses)))\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    "    AnswerRelevancyEvaluator\n",
    ")\n",
    "\n",
    "judges = {}\n",
    "judges[\"answer_relevancy\"] = AnswerRelevancyEvaluator()\n",
    "judges[\"correctness\"] = CorrectnessEvaluator()\n",
    "judges[\"semantic_similarity\"] = SemanticSimilarityEvaluator()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "evals = {\n",
    "    \"correctness\": [],\n",
    "    \"answer_relevancy\": [],\n",
    "    \"semantic_similarity\": []\n",
    "}\n",
    "\n",
    "for query, response, reference in tqdm.tqdm(\n",
    "    zip(queries, responses, references)\n",
    "):\n",
    "    \n",
    "    correctness_result = judges[\"correctness\"].evaluate(\n",
    "        query=query,\n",
    "        response=response,\n",
    "        reference=reference\n",
    "    )\n",
    "\n",
    "    answer_relevancy_result = judges[\"answer_relevancy\"].evaluate(\n",
    "        query=query,\n",
    "        response=response\n",
    "    )\n",
    "\n",
    "\n",
    "    semantic_similarity_result = judges[\"semantic_similarity\"].evaluate(\n",
    "        query=query,\n",
    "        response=response,\n",
    "        reference=reference,\n",
    "    )\n",
    "    \n",
    "    evals[\"correctness\"].append(correctness_result)\n",
    "    evals[\"answer_relevancy\"].append(answer_relevancy_result)\n",
    "    evals[\"semantic_similarity\"].append(semantic_similarity_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Queries': queries,\n",
    "    'Answers': responses,\n",
    "    'References': references,\n",
    "    \"Correctness score\": list(map(lambda obj: obj.score, evals[\"correctness\"])),\n",
    "    \"Correctness passing\": list(map(lambda obj: obj.passing, evals[\"correctness\"])),\n",
    "    \"Relevancy score\": list(map(lambda obj: obj.score, evals[\"answer_relevancy\"])),\n",
    "    \"Relevancy passing\": list(map(lambda obj: obj.passing, evals[\"answer_relevancy\"])),\n",
    "    \"Semantic similarity score\": list(map(lambda obj: obj.score, evals[\"semantic_similarity\"])),\n",
    "    \"Semantic similarity passing\": list(map(lambda obj: obj.passing, evals[\"semantic_similarity\"])),\n",
    "})\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.to_csv(f\"{PROJECT_PATH}/results.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"{PROJECT_PATH}/results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}