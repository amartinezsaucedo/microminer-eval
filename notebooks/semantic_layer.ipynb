{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"semantic-router[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/Documents/Proyectos/microminer-eval/.venv/lib/python3.11/site-packages/ema_workbench/em_framework/__init__.py:101: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  warnings.warn(\"ipyparallel not installed - IpyparalleEvaluator not available\")\n"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "from semantic_router.layer import RouteLayer\n",
    "from IPython.display import Markdown\n",
    "from ema_workbench import load_results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecompositionSpace:\n",
    "    def __init__(self, project_path, project_name):\n",
    "        model_filename = f\"{project_path}/{project_name}_128scenarios_nopolicies_sobol\" #.tar.gz'\n",
    "        experiments_df, outcomes = load_results(model_filename+ '.tar.gz')\n",
    "        self.outcomes = pd.DataFrame(outcomes)\n",
    "        self.experiments = experiments_df\n",
    "        with open(model_filename+'_model.pkl', 'rb') as input:\n",
    "            self.uncertainties_problem = pickle.load(input)\n",
    "        with open(model_filename+'_partitions.pkl', 'rb') as input:\n",
    "            self.partitions = pickle.load(input)\n",
    "        similarity_filename = f\"{project_path}/{project_name}_omega_scores.csv\"\n",
    "        self.partitions_distance = 1 - pd.read_csv(similarity_filename, index_col=0)\n",
    "        stable_solutions_filename = f\"{project_path}/{project_name}_stable_solutions.pkl\"\n",
    "        with open(stable_solutions_filename, 'rb') as f:\n",
    "             self.stable_solutions = pickle.load(f)\n",
    "             self.other_labels = self.stable_solutions.keys()\n",
    "        mds = MDS(dissimilarity='precomputed', random_state=0)\n",
    "        self.embeddings_2d_partitions = mds.fit_transform(self.partitions_distance)\n",
    "        partition_labels_2d, _, silhouette = self.run_agglomerative(self.embeddings_2d_partitions, k=5, threshold=None, \n",
    "                                                       show_dendogram=True, normalize=True, n_pca=2)\n",
    "        self.partition_labels = partition_labels_2d\n",
    "\n",
    "    def run_agglomerative(self, df, k, threshold=200, n_pca=None, normalize=False, show_dendogram=False, archstructure=None):    \n",
    "      if normalize:\n",
    "        sample = StandardScaler().fit_transform(df)\n",
    "      else:\n",
    "        sample = df.values\n",
    "    \n",
    "      if n_pca is not None:\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        sample_pca = sample\n",
    "        model = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='ward',\n",
    "                                        connectivity=archstructure, distance_threshold=threshold)\n",
    "        model.fit(sample_pca)\n",
    "        X = sample_pca\n",
    "      else:\n",
    "        model = AgglomerativeClustering(n_clusters=k, affinity='precomputed', linkage='single',\n",
    "                                      connectivity=archstructure, distance_threshold=threshold)\n",
    "        model.fit(sample)\n",
    "      labels = model.labels_\n",
    "      fixed_labels = np.where(model.labels_ < 0, 0, model.labels_)\n",
    "      classes = set(fixed_labels)\n",
    "      if len(classes) > 1:\n",
    "        if n_pca is not None:\n",
    "          silhouette = metrics.silhouette_score(sample_pca, fixed_labels)\n",
    "        else:\n",
    "          silhouette = metrics.silhouette_score(sample, fixed_labels)\n",
    "      else:\n",
    "        silhouette = 0.0    \n",
    "      return fixed_labels, model, silhouette\n",
    "\n",
    "    def get_decompositions_by_metric(self, metric: str, k: int, asc: bool) -> list:\n",
    "        return self.outcomes.sort_values(by=[metric], ascending=[asc]).head(k)\n",
    "\n",
    "    def get_xy_coordinates(self, labels, embeddings_2d, distance_df):\n",
    "        xy_coordinates = []\n",
    "        for lb in labels:\n",
    "            idx = list(distance_df.columns).index(lb)\n",
    "            xy_coordinates.append(embeddings_2d[idx])\n",
    "        return xy_coordinates\n",
    "\n",
    "    def get_decomposition_space(self, labels: [] = []) -> plt.plot: \n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        df = pd.DataFrame(self.embeddings_2d_partitions, columns=['x', 'y'])\n",
    "        df['cluster'] = self.partition_labels \n",
    "        ax = sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", alpha=0.3, legend='full', sizes=(20, 200))\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(ylabel=None)\n",
    "        if len(labels) > 0:\n",
    "            medoids = np.array(self.get_xy_coordinates(labels, self.embeddings_2d_partitions, self.partitions_distance))\n",
    "            ax.plot(medoids[:,0], medoids[:,1], 'X', markersize=9, alpha=0.7, color='black')\n",
    "            for idx, lb in enumerate(labels):\n",
    "                    ax.annotate(lb, (medoids[idx,0], medoids[idx,1]))\n",
    "            \n",
    "        plt.grid(False)\n",
    "        return plt\n",
    "\n",
    "    #TODO translate/map quality attributes to metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SemanticLayer:\n",
    "    SYSTEM_PROMPT = \"\"\"Your are an expert software architect that assists users to explore and understand a de.\n",
    "        You have a deep understanding of monolith to microservices migration and microservices quality metrics.\n",
    "        Your role is to help users to understand the decomposition space to pick the most suitable microservices decomposition according to the user need.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, decomposition_space=None) -> None:\n",
    "        self.llm = Groq(model=\"llama3-8b-8192\", api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "        self.agent = None\n",
    "        self.intent_detector = None\n",
    "        self.decomposition_space = decomposition_space\n",
    "\n",
    "\n",
    "    def show_decomposition_space(self) -> plt.plot:\n",
    "        \"\"\" Gets the decomposition space (plot)\n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space\n",
    "        \"\"\"\n",
    "        return self.decomposition_space.get_decomposition_space().show()\n",
    "\n",
    "    def get_decomposition_by_metric(self, k: int, metric: str, asc: bool) -> pd.DataFrame:\n",
    "        \"\"\" Gets the K decompositions matching a metric condition\n",
    "\n",
    "          Args:\n",
    "            k (int): The number of decompositions to retrieve.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to obtain the decompositions that match a metric higher or lower\n",
    "    \n",
    "        Returns:\n",
    "            pd.DataFrame: The K decompositions ordered by asc param against the metric passed as parameter.\n",
    "        \"\"\"\n",
    "        return self.decomposition_space.get_decompositions_by_metric(metric, k, asc)\n",
    "\n",
    "    def show_decomposition_in_space(self, k: int, metric: str, asc: bool) -> plt.plot:\n",
    "        \"\"\" Show in the decomposition space (plot) the desired K decompositions matching a metric condition\n",
    "\n",
    "        Args:\n",
    "            k (int): The number of decompositions to show.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to show the decompositions that match a metric higher or lower\n",
    "    \n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space with the decompositions found\n",
    "        \"\"\"\n",
    "        decompositions = self.decomposition_space.get_decompositions_by_metric(metric, k, asc)\n",
    "        indexes = decompositions.index.values\n",
    "        labels = []\n",
    "        for index in indexes:\n",
    "            value = self.decomposition_space.experiments.iloc[index]\n",
    "            print(value)\n",
    "            labels.append(f\"resolution_{value['resolution']}_k_{value['k']}\")\n",
    "        return self.decomposition_space.get_decomposition_space(labels).show()\n",
    "\n",
    "   \n",
    "    def _get_tools(self):\n",
    "        return [ # All the functions that the agent can execute\n",
    "            FunctionTool.from_defaults(fn=self.show_decomposition_space, return_direct=True),\n",
    "            FunctionTool.from_defaults(fn=self.get_decomposition_by_metric, return_direct=True),\n",
    "            FunctionTool.from_defaults(fn=self.show_decomposition_in_space, return_direct=True),\n",
    "        ]\n",
    "\n",
    "    def _configure_routes():\n",
    "        return [\n",
    "            Route(\n",
    "                name=\"show_decomposition_space\",\n",
    "                utterances=[\n",
    "                    \"Which decompositions are generated?\",\n",
    "                    \"Show me the decomposition space graphically\",\n",
    "                    \"Get all decompositions graphically\",\n",
    "                    \"Show me all decompositions\",\n",
    "                    \"Show the decomposition space\",\n",
    "                    \"Show the decomposition space graphically\"\n",
    "                ],\n",
    "                description=\"Show the decomposition space graphically.\"\n",
    "            ),\n",
    "            Route(\n",
    "                name=\"get_decomposition_by_metric\",\n",
    "                utterances=[\n",
    "                    \"Get the X decompositions with less Y\",\n",
    "                    \"Get me X decompositions with more Y\",\n",
    "                    \"Which is the decomposition with more X?\",\n",
    "                    \"Which is the decomposition with less X?\",\n",
    "                    \"Which is the decomposition of highest X?\",\n",
    "                    \"Which is the decomposition of lowest X?\",\n",
    "                ],\n",
    "                description=\"Get the K decompositions that match a preferring metric.\"\n",
    "            ),\n",
    "            Route(\n",
    "                name=\"show_decomposition_in_space\",\n",
    "                utterances=[\n",
    "                    \"Show me the decomposition with more X\",\n",
    "                    \"Get a plot of the decomposition X\",\n",
    "                    \"Show me the decomposition with more X graphically\",\n",
    "                    \"Show me the decomposition with lowest X graphically\",\n",
    "                    \"Show me the decomposition with highest X graphically\",\n",
    "                    \"Show me the decomposition of lowest X graphically\",\n",
    "                    \"Show me the decomposition of highest X graphically\",\n",
    "                ],\n",
    "                description=\"Show the K decompositions that match a preferring metric in the decomposition space.\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.agent.reset()\n",
    "\n",
    "    def chat(self, question, return_intent=False):\n",
    "        if self.agent is None: \n",
    "            tools = self._get_tools()\n",
    "            self.agent = OpenAIAgent.from_tools(tools, llm=self.llm, system_prompt=SemanticLayer.SYSTEM_PROMPT, verbose=True)\n",
    "            encoder = HuggingFaceEncoder()\n",
    "            self.intent_detector = RouteLayer(encoder=encoder, routes=SemanticLayer._configure_routes(), llm=self.llm)\n",
    "\n",
    "        intent  = self.intent_detector(question)\n",
    "        print(\"Intent detected:\", intent.name)\n",
    "\n",
    "        if intent.name is None:\n",
    "            msg = \"I'm sorry, I did not understand your question or I'm no able to answer it. Please try again...\"\n",
    "            if return_intent:\n",
    "                return None\n",
    "            return display(Markdown(f\"<b>{msg}</b>\"))\n",
    "\n",
    "        function_name = \"\\nTry to execute tool \"+intent.name if (intent.name is not None) and (intent.name != 'misc') else \"\"\n",
    "        response = self.agent.chat(question+function_name)\n",
    "\n",
    "        if response.sources is None or len(response.sources) == 0:\n",
    "            return display(Markdown(f\"<b>{response.response}</b>\"))\n",
    "\n",
    "        obj = response.sources[0].raw_output\n",
    "\n",
    "        show_op = getattr(obj, \"show\", None)\n",
    "        if callable(show_op):\n",
    "            msg =  \"This is a graphical representation of the results for your question.\"\n",
    "            display(Markdown(f\"<b>{msg}</b>\"))\n",
    "            show_op()\n",
    "            return None\n",
    "        if return_intent:\n",
    "            return intent.name, response.sources[0].raw_input.get(\"kwargs\"), response\n",
    "        return obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decomposition_space = DecompositionSpace(\"../jpetstore\", \"jpetstore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer = SemanticLayer(decomposition_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Get the 10 decompositions with higher density\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Get the decomposition with lowest ned\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Which is the decomposition of highest modularity?\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Show me the decomposition with highest density graphically\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer.chat(\"Show me the 10 decompositions with lowest modularity graphically\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(layer.chat(\"Show me the 10 decompositions with lowest modularity graphically\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, RelevancyEvaluator\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Response\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.prompts.base import BasePromptTemplate, PromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Settings.llm = Groq(model=\"llama3-8b-8192\", api_key=\"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\", base_url=\"https://api.groq.com/openai/v1\")\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEFAULT_TEXT_QA_PROMPT = \"\"\"\\\n",
    "Context information is below.\n",
    "The only available metrics are ned, density, and modularity\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Based on the following function documentation, generate natural questions that someone might ask and this function answer. The answer should always be the function name along its arguments. The questions should relate to its description and expected outcomes in a conversational manner, also to the example questions. The documentation is as follows\n",
    "{query_str}\n",
    "\"\"\"\n",
    "text_question_template = PromptTemplate(DEFAULT_TEXT_QA_PROMPT)\n",
    "text_qa_template = DEFAULT_TEXT_QA_PROMPT\n",
    "question_gen_query = (f\"You are a Teacher/Professor. Your task is to setup \\\n",
    "                        5 questions for an upcoming \\\n",
    "                        quiz/examination. The questions should be diverse in nature \\\n",
    "                            across the document. Restrict the questions to the \\\n",
    "                                context information provided. Tip: use the example questions as base\" )\n",
    "    \n",
    "documentation = [Document(text=\"\"\"\n",
    "        Function: show_decomposition_in_space\n",
    "        Example questions:  \"Show me the decomposition with more X\",\n",
    "                    \"Get a plot of the decomposition X\",\n",
    "                    \"Show me the decomposition with more X graphically\",\n",
    "                    \"Show me the decomposition with lowest X graphically\",\n",
    "                    \"Show me the decomposition with highest X graphically\",\n",
    "                    \"Show me the decomposition of lowest X graphically\",\n",
    "                    \"Show me the decomposition of highest X graphically\",\n",
    "        Description: Show in the decomposition space (plot) the desired K decompositions matching a metric condition\n",
    "\n",
    "        Args:\n",
    "            k (int): The number of decompositions to show.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to show the decompositions that match a metric higher or lower\n",
    "    \n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space with the decompositions found\"\"\"),\n",
    "                Document(text=\"\"\"\n",
    "                Function: get_decomposition_by_metric\n",
    "                Example questions:  \"Get the X decompositions with less Y\",\n",
    "                    \"Get me X decompositions with more Y\",\n",
    "                    \"Which is the decomposition with more X?\",\n",
    "                    \"Which is the decomposition with less X?\",\n",
    "                    \"Which is the decomposition of highest X?\",\n",
    "                    \"Which is the decomposition of lowest X?\",\n",
    "                Description: Gets the K decompositions matching a metric condition\n",
    "\n",
    "          Args:\n",
    "            k (int): The number of decompositions to retrieve.\n",
    "            metric (str): The metric to match the decompositions against.\n",
    "            asc (bool): Whether to obtain the decompositions that match a metric higher or lower\n",
    "    \n",
    "        Returns:\n",
    "            pd.DataFrame: The K decompositions ordered by asc param against the metric passed as parameter.\n",
    "            \"\"\"),\n",
    "                Document(text=\"\"\"\n",
    "                Function: show_decomposition_space\n",
    "                Example questions:  \"Which decompositions are generated?\",\n",
    "                    \"Show me the decomposition space graphically\",\n",
    "                    \"Get all decompositions graphically\",\n",
    "                    \"Show me all decompositions\",\n",
    "                    \"Show the decomposition space\",\n",
    "                    \"Show the decomposition space graphically\"\n",
    "                Description: Gets the decomposition space (plot)\n",
    "\n",
    "        Returns:\n",
    "            plt.plot: The plot of the decomposition space\n",
    "            \"\"\")]\n",
    "data_generator = DatasetGenerator.from_documents(documentation, text_question_template=text_question_template, text_qa_template=text_qa_template, question_gen_query=question_gen_query)\n",
    "eval_questions = data_generator.generate_questions_from_nodes()\n",
    "eval_questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator = RelevancyEvaluator()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documentation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_eval_df(query: str, response: Response, eval_result: str) -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Query\": [query],\n",
    "            \"Response\": [str(response)],\n",
    "            \"Source\": [(\n",
    "                response.source_nodes[0].node.get_content()[:1000] + \"...\"\n",
    "            )],\n",
    "            \"Evaluation Result\": [eval_result.passing],\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response_vector, args, response = layer.chat(eval_questions[3], return_intent = True)\n",
    "response2 = f\"{response_vector}(\"\n",
    "response2 += ', '.join(f\"{key}={value!r}\" for key, value in args.items())\n",
    "response2 += \")\"\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_result = evaluator.evaluate_response(\n",
    "    query=eval_questions[3], response=response\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_result = evaluator.evaluate_response(\n",
    "    query=eval_questions[4], response=response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_questions[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}